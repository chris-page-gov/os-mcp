{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8657b8dd",
   "metadata": {},
   "source": [
    "# OS MCP Server Examples: Nottingham & Coventry\n",
    "\n",
    "This notebook demonstrates the functionality of the **OS MCP Server** using real UK locations:\n",
    "- **Nottingham NG1 7FG** - City center location \n",
    "- **Coventry CV1** - City center area\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to connect to the OS MCP Server\n",
    "- Basic geospatial queries and searches\n",
    "- Working with UK Ordnance Survey data\n",
    "- Advanced filtering and location-based operations\n",
    "- Real-world examples with actual UK postcodes\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- OS API key from [OS Data Hub](https://osdatahub.os.uk/) set as `OS_API_KEY` environment variable\n",
    "- Python environment with required dependencies (automatically installed)\n",
    "\n",
    "## Automatic Setup\n",
    "\n",
    "🚀 **This notebook will automatically:**\n",
    "- Install required Python packages\n",
    "- Start the OS MCP Server if not already running\n",
    "- Handle all connections and setup\n",
    "- Clean up when finished\n",
    "\n",
    "**No manual server setup required!** Just run the cells in order and explore the data.\n",
    "\n",
    "Let's explore the rich geospatial data available through the OS MCP Server! 🗺️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7521f1",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "First, let's install any required packages and import the libraries we need for connecting to the OS MCP Server and handling geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb625c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Checking and installing required packages...\n",
      "✅ mcp already installed\n",
      "📦 Installing matplotlib...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "✅ mcp already installed\n",
      "📦 Installing matplotlib...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_26_aarch64.manylinux_2_28_aarch64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_26_aarch64.manylinux_2_28_aarch64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.2 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.2 kB)\n",
      "Collecting numpy>=1.23 (from matplotlib)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "Collecting numpy>=1.23 (from matplotlib)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/8.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_26_aarch64.manylinux_2_28_aarch64.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.2/329.2 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_26_aarch64.manylinux_2_28_aarch64.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.2/329.2 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.59.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/14.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.2 pillow-11.3.0 pyparsing-3.2.3\n",
      "📦 Installing pandas...\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.2 pillow-11.3.0 pyparsing-3.2.3\n",
      "📦 Installing pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/11.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0mCollecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "✅ numpy already installed\n",
      "\n",
      "✅ All packages checked/installed!\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "✅ numpy already installed\n",
      "\n",
      "✅ All packages checked/installed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "✅ Matplotlib inline plotting enabled\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (if not already installed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✅ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install all required packages\n",
    "required_packages = [\n",
    "    \"mcp\",\n",
    "    \"matplotlib\", \n",
    "    \"pandas\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "print(\"🔄 Checking and installing required packages...\")\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n✅ All packages checked/installed!\")\n",
    "\n",
    "# Import required libraries\n",
    "import asyncio\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any, List\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import MCP client libraries\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from mcp import ClientSession\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "\n",
    "# Configure logging for better visibility\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enable matplotlib inline plotting for Jupyter\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    print(\"✅ Matplotlib inline plotting enabled\")\n",
    "except:\n",
    "    print(\"ℹ️ Not in Jupyter environment - matplotlib will use default backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f61dec",
   "metadata": {},
   "source": [
    "## 2. Initialize OS MCP Client and Auto-Start Server\n",
    "\n",
    "The next cells will:\n",
    "1. **Configure connection settings** for the OS MCP Server\n",
    "2. **Automatically check** if the server is running\n",
    "3. **Start the server** if needed (no manual setup required!)\n",
    "4. **Verify** everything is ready for data exploration\n",
    "\n",
    "Make sure you have your OS API key set in the `OS_API_KEY` environment variable. The notebook handles everything else automatically! 🎯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7364a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OS_API_KEY environment variable detected\n",
      "🌍 Example locations configured:\n",
      "  📍 Nottingham NG1 7FG at (52.9548, -1.1543)\n",
      "  📍 Coventry CV1 at (52.4081, -1.5101)\n",
      "🔌 Server URL: http://localhost:8000/mcp/\n",
      "🔑 Authentication: Bearer token configured\n"
     ]
    }
   ],
   "source": [
    "# Configuration for OS MCP Server\n",
    "SERVER_URL = \"http://localhost:8000/mcp/\"\n",
    "HEADERS = {\"Authorization\": \"Bearer dev-token\"}\n",
    "\n",
    "# Example locations we'll be working with\n",
    "LOCATIONS = {\n",
    "    \"nottingham\": {\n",
    "        \"name\": \"Nottingham NG1 7FG\",\n",
    "        \"postcode\": \"NG1 7FG\", \n",
    "        \"lat\": 52.9548,\n",
    "        \"lon\": -1.1543,\n",
    "        \"bbox\": [-1.16, 52.95, -1.15, 52.96]  # [min_lon, min_lat, max_lon, max_lat]\n",
    "    },\n",
    "    \"coventry\": {\n",
    "        \"name\": \"Coventry CV1\",\n",
    "        \"postcode\": \"CV1\",\n",
    "        \"lat\": 52.4081,\n",
    "        \"lon\": -1.5101,\n",
    "        \"bbox\": [-1.52, 52.40, -1.50, 52.42]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper function to extract text from MCP responses\n",
    "def extract_text_from_result(result):\n",
    "    \"\"\"Safely extract text from MCP tool result\"\"\"\n",
    "    try:\n",
    "        if result.content and len(result.content) > 0:\n",
    "            content = result.content[0]\n",
    "            if hasattr(content, 'text'):\n",
    "                return content.text\n",
    "            else:\n",
    "                return str(content)\n",
    "        return \"No response\"\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {e}\"\n",
    "\n",
    "# Check environment variables\n",
    "if not os.environ.get(\"OS_API_KEY\"):\n",
    "    print(\"⚠️ WARNING: OS_API_KEY environment variable not set!\")\n",
    "    print(\"💡 Get your API key from: https://osdatahub.os.uk/\")\n",
    "else:\n",
    "    print(\"✅ OS_API_KEY environment variable detected\")\n",
    "\n",
    "print(f\"🌍 Example locations configured:\")\n",
    "for key, loc in LOCATIONS.items():\n",
    "    print(f\"  📍 {loc['name']} at ({loc['lat']}, {loc['lon']})\")\n",
    "    \n",
    "print(f\"🔌 Server URL: {SERVER_URL}\")\n",
    "print(f\"🔑 Authentication: Bearer token configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8251fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if OS MCP Server is running and start it if needed\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import signal\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def is_server_running(url=\"http://localhost:8000\", timeout=2):\n",
    "    \"\"\"Check if the OS MCP Server is running\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/\", timeout=timeout)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_server():\n",
    "    \"\"\"Start the OS MCP Server in the background\"\"\"\n",
    "    print(\"🚀 Starting OS MCP Server...\")\n",
    "    \n",
    "    # Get the path to the server script\n",
    "    current_dir = Path.cwd()\n",
    "    if current_dir.name == \"examples\":\n",
    "        server_path = current_dir.parent / \"src\" / \"server.py\"\n",
    "    else:\n",
    "        server_path = current_dir / \"src\" / \"server.py\"\n",
    "    \n",
    "    if not server_path.exists():\n",
    "        print(f\"❌ Server script not found at {server_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Start the server process\n",
    "    try:\n",
    "        # Start server in background with streamable-http transport\n",
    "        process = subprocess.Popen([\n",
    "            \"python\", str(server_path),\n",
    "            \"--transport\", \"streamable-http\",\n",
    "            \"--host\", \"0.0.0.0\", \n",
    "            \"--port\", \"8000\"\n",
    "        ], \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE,\n",
    "        preexec_fn=os.setsid  # Create new process group\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Server process started with PID: {process.pid}\")\n",
    "        \n",
    "        # Wait a bit for server to start\n",
    "        print(\"⏱️ Waiting for server to start...\")\n",
    "        for i in range(10):\n",
    "            time.sleep(1)\n",
    "            if is_server_running():\n",
    "                print(\"✅ Server is now running and responding!\")\n",
    "                return process\n",
    "            print(f\"   Waiting... ({i+1}/10)\")\n",
    "        \n",
    "        print(\"⚠️ Server started but may not be fully ready yet\")\n",
    "        return process\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to start server: {e}\")\n",
    "        return None\n",
    "\n",
    "# Check if server is already running\n",
    "print(\"🔍 Checking if OS MCP Server is already running...\")\n",
    "if is_server_running():\n",
    "    print(\"✅ OS MCP Server is already running on port 8000\")\n",
    "    server_process = None\n",
    "else:\n",
    "    print(\"⚠️ OS MCP Server is not running - starting it now...\")\n",
    "    server_process = start_server()\n",
    "\n",
    "# Store the process for cleanup later\n",
    "if 'server_process' not in globals():\n",
    "    server_process = None\n",
    "\n",
    "print(f\"\\n📋 Server Status Summary:\")\n",
    "print(f\"   🌐 Server URL: {SERVER_URL}\")\n",
    "print(f\"   🔑 Authentication: Bearer token\")\n",
    "print(f\"   📊 Process: {'Running' if server_process else 'Already running or failed'}\")\n",
    "print(f\"   ✅ Ready for connections!\")\n",
    "\n",
    "# Final verification\n",
    "if is_server_running():\n",
    "    print(\"\\n🎉 OS MCP Server is ready for notebook operations!\")\n",
    "else:\n",
    "    print(\"\\n❌ Server may not be responding - please check the terminal for errors\")\n",
    "    print(\"💡 You can also start the server manually with:\")\n",
    "    print(\"   cd /workspaces/os-mcp && python src/server.py --transport streamable-http --port 8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf239e",
   "metadata": {},
   "source": [
    "## 3. Connect to OS MCP Server and Basic Operations\n",
    "\n",
    "Now we'll establish a connection to the server. The server should already be running from the previous cell, but if there are any connection issues, the notebook will provide helpful diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d70f6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 Connecting to OS MCP Server...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "Cancelled by cancel scope ffff6c137390",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWouldBlock\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/anyio/streams/memory.py:111\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_nowait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WouldBlock:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Add ourselves in the queue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/anyio/streams/memory.py:106\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive_nowait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m WouldBlock\n",
      "\u001b[31mWouldBlock\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m client_manager = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# This needs to be run in an async context\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     session, client_manager = \u001b[38;5;28;01mawait\u001b[39;00m connect_to_server()\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m test_basic_operations(session)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 Basic operations completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mconnect_to_server\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session.\u001b[34m__aenter__\u001b[39m()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Initialize the session\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m init_result = \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m     16\u001b[39m session_id = get_session_id()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Connected successfully! Session ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/mcp/client/session.py:151\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m elicitation = (\n\u001b[32m    140\u001b[39m     types.ElicitationCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elicitation_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_elicitation_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m )\n\u001b[32m    142\u001b[39m roots = (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    152\u001b[39m     types.ClientRequest(\n\u001b[32m    153\u001b[39m         types.InitializeRequest(\n\u001b[32m    154\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    156\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    157\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    158\u001b[39m                     sampling=sampling,\n\u001b[32m    159\u001b[39m                     elicitation=elicitation,\n\u001b[32m    160\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    161\u001b[39m                     roots=roots,\n\u001b[32m    162\u001b[39m                 ),\n\u001b[32m    163\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    164\u001b[39m             ),\n\u001b[32m    165\u001b[39m         )\n\u001b[32m    166\u001b[39m     ),\n\u001b[32m    167\u001b[39m     types.InitializeResult,\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/mcp/shared/session.py:272\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         response_or_error = \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader.receive()\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/anyio/streams/memory.py:119\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._state.waiting_receivers[receive_event] = receiver\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m receive_event.wait()\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._state.waiting_receivers.pop(receive_event, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled by cancel scope ffff6c137390"
     ]
    }
   ],
   "source": [
    "async def connect_to_server():\n",
    "    \"\"\"Establish connection to OS MCP Server\"\"\"\n",
    "    print(\"🔌 Connecting to OS MCP Server...\")\n",
    "    \n",
    "    try:\n",
    "        # Create client connection\n",
    "        client_manager = streamablehttp_client(SERVER_URL, headers=HEADERS)\n",
    "        read_stream, write_stream, get_session_id = await client_manager.__aenter__()\n",
    "        \n",
    "        # Create MCP session\n",
    "        session = ClientSession(read_stream, write_stream)\n",
    "        await session.__aenter__()\n",
    "        \n",
    "        # Initialize the session\n",
    "        init_result = await session.initialize()\n",
    "        session_id = get_session_id()\n",
    "        \n",
    "        print(f\"✅ Connected successfully! Session ID: {session_id}\")\n",
    "        \n",
    "        return session, client_manager\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "async def test_basic_operations(session):\n",
    "    \"\"\"Test basic server operations\"\"\"\n",
    "    print(\"\\n🧪 Testing basic operations...\")\n",
    "    \n",
    "    # 1. Hello world test\n",
    "    print(\"\\n👋 Testing hello world...\")\n",
    "    try:\n",
    "        result = await session.call_tool(\"hello_world\", {\"name\": \"Nottingham Explorer\"})\n",
    "        response = extract_text_from_result(result)\n",
    "        print(f\"✅ Hello world response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Hello world failed: {e}\")\n",
    "    \n",
    "    # 2. Check API key\n",
    "    print(\"\\n🔑 Checking API key status...\")\n",
    "    try:\n",
    "        result = await session.call_tool(\"check_api_key\", {})\n",
    "        response = extract_text_from_result(result)\n",
    "        api_status = json.loads(response)\n",
    "        if api_status.get(\"status\") == \"success\":\n",
    "            print(f\"✅ {api_status.get('message')}\")\n",
    "        else:\n",
    "            print(f\"❌ {api_status.get('message')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ API key check failed: {e}\")\n",
    "    \n",
    "    # 3. List available tools\n",
    "    print(\"\\n🔍 Listing available tools...\")\n",
    "    try:\n",
    "        tools_result = await session.list_tools()\n",
    "        tools = [tool.name for tool in tools_result.tools]\n",
    "        print(f\"✅ Found {len(tools)} tools:\")\n",
    "        for i, tool in enumerate(tools, 1):\n",
    "            print(f\"  {i}. {tool}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Tool listing failed: {e}\")\n",
    "\n",
    "# Run the connection and basic tests\n",
    "session = None\n",
    "client_manager = None\n",
    "\n",
    "try:\n",
    "    # This needs to be run in an async context\n",
    "    session, client_manager = await connect_to_server()\n",
    "    await test_basic_operations(session)\n",
    "    print(\"\\n🎉 Basic operations completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"💥 Basic operations failed: {e}\")\n",
    "    if session:\n",
    "        try:\n",
    "            await session.__aexit__(None, None, None)\n",
    "        except:\n",
    "            pass\n",
    "    if client_manager:\n",
    "        try:\n",
    "            await client_manager.__aexit__(None, None, None) \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fd148",
   "metadata": {},
   "source": [
    "## 4. Get Workflow Context and Available Collections\n",
    "\n",
    "Before we can perform any searches, we need to get the workflow context. This is a required step that tells us what data collections are available and how to filter them effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_workflow_context(session):\n",
    "    \"\"\"Get the workflow context - required before any searches\"\"\"\n",
    "    print(\"🎯 Getting workflow context (required for all searches)...\")\n",
    "    \n",
    "    try:\n",
    "        result = await session.call_tool(\"get_workflow_context\", {})\n",
    "        response_text = extract_text_from_result(result)\n",
    "        context_data = json.loads(response_text)\n",
    "        \n",
    "        print(\"✅ Workflow context retrieved successfully!\")\n",
    "        \n",
    "        # Show available collections\n",
    "        if \"available_collections\" in context_data:\n",
    "            collections = context_data[\"available_collections\"]\n",
    "            print(f\"\\n📊 Found {len(collections)} data collections:\")\n",
    "            \n",
    "            # Create a summary dataframe\n",
    "            collection_summary = []\n",
    "            for coll_id, coll_info in collections.items():\n",
    "                collection_summary.append({\n",
    "                    \"Collection ID\": coll_id,\n",
    "                    \"Title\": coll_info.get(\"title\", \"No title\"),\n",
    "                    \"Has Enum Filters\": coll_info.get(\"has_enum_filters\", False),\n",
    "                    \"Total Queryables\": coll_info.get(\"total_queryables\", 0),\n",
    "                    \"Enum Count\": coll_info.get(\"enum_count\", 0)\n",
    "                })\n",
    "            \n",
    "            df = pd.DataFrame(collection_summary)\n",
    "            print(df.to_string(index=False))\n",
    "            \n",
    "        return context_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to get workflow context: {e}\")\n",
    "        raise\n",
    "\n",
    "async def list_collections_detail(session):\n",
    "    \"\"\"Get detailed collection information\"\"\"\n",
    "    print(\"\\n📚 Getting detailed collection information...\")\n",
    "    \n",
    "    try:\n",
    "        result = await session.call_tool(\"list_collections\", {})\n",
    "        response_text = extract_text_from_result(result)\n",
    "        collections_data = json.loads(response_text)\n",
    "        \n",
    "        if \"collections\" in collections_data:\n",
    "            collections = collections_data[\"collections\"]\n",
    "            print(f\"✅ Found {len(collections)} collections with details:\")\n",
    "            \n",
    "            for i, collection in enumerate(collections[:5], 1):  # Show first 5\n",
    "                coll_id = collection.get(\"id\", \"Unknown ID\")\n",
    "                title = collection.get(\"title\", \"No title\")\n",
    "                print(f\"  {i}. {coll_id}: {title}\")\n",
    "            \n",
    "            if len(collections) > 5:\n",
    "                print(f\"  ... and {len(collections) - 5} more collections\")\n",
    "                \n",
    "        return collections_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to list collections: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Get workflow context and collections\n",
    "if session:\n",
    "    try:\n",
    "        workflow_context = await get_workflow_context(session)\n",
    "        collections_data = await list_collections_detail(session)\n",
    "        print(\"\\n🎉 Workflow context and collections loaded successfully!\")\n",
    "        \n",
    "        # Show some key information about filtering\n",
    "        if \"QUICK_FILTERING_GUIDE\" in workflow_context:\n",
    "            print(\"\\n💡 Quick filtering tips:\")\n",
    "            print(\"  • Use exact enum values for precise filtering\")\n",
    "            print(\"  • Always explain your plan before making searches\")\n",
    "            print(\"  • Use the 'filter' parameter for all filtering operations\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"💥 Workflow context failed: {e}\")\n",
    "else:\n",
    "    print(\"❌ No active session - please run the connection cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1e0c7",
   "metadata": {},
   "source": [
    "## 5. Location-Based Searches: Nottingham NG1 7FG and Coventry CV1\n",
    "\n",
    "Now let's perform real searches around our example locations. We'll search for streets, buildings, and land use features in both Nottingham and Coventry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222915c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_streets_around_location(session, location_name, bbox):\n",
    "    \"\"\"Search for streets around a specific location\"\"\"\n",
    "    print(f\"🛣️ Searching for streets around {location_name}...\")\n",
    "    \n",
    "    try:\n",
    "        bbox_str = \",\".join(map(str, bbox))\n",
    "        \n",
    "        result = await session.call_tool(\"search_features\", {\n",
    "            \"collection_id\": \"trn-ntwk-street-1\",\n",
    "            \"bbox\": bbox_str,\n",
    "            \"limit\": 10\n",
    "        })\n",
    "        \n",
    "        response_text = extract_text_from_result(result)\n",
    "        street_data = json.loads(response_text)\n",
    "        \n",
    "        if \"features\" in street_data:\n",
    "            features = street_data[\"features\"]\n",
    "            print(f\"✅ Found {len(features)} streets around {location_name}\")\n",
    "            \n",
    "            # Create a summary of streets found\n",
    "            street_summary = []\n",
    "            for feature in features[:5]:  # Show first 5\n",
    "                props = feature.get(\"properties\", {})\n",
    "                street_summary.append({\n",
    "                    \"Street Name\": props.get(\"designatedname1_text\", \"Unnamed street\"),\n",
    "                    \"Road Classification\": props.get(\"roadclassification\", \"Unknown\"),\n",
    "                    \"Operational State\": props.get(\"operationalstate\", \"Unknown\"),\n",
    "                    \"Road Number\": props.get(\"roadnumber\", \"N/A\")\n",
    "                })\n",
    "            \n",
    "            if street_summary:\n",
    "                df = pd.DataFrame(street_summary)\n",
    "                print(df.to_string(index=False))\n",
    "            \n",
    "            return street_data\n",
    "        else:\n",
    "            print(f\"⚠️ No streets found around {location_name}\")\n",
    "            return {}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Street search failed for {location_name}: {e}\")\n",
    "        return {}\n",
    "\n",
    "async def find_land_use_around_location(session, location_name, bbox, land_use_type):\n",
    "    \"\"\"Find specific land use features around a location\"\"\"\n",
    "    print(f\"\\n🏢 Searching for {land_use_type} around {location_name}...\")\n",
    "    \n",
    "    try:\n",
    "        bbox_str = \",\".join(map(str, bbox))\n",
    "        \n",
    "        result = await session.call_tool(\"search_features\", {\n",
    "            \"collection_id\": \"lus-fts-site-1\",\n",
    "            \"bbox\": bbox_str,\n",
    "            \"filter\": f\"oslandusetertiarygroup = '{land_use_type}'\",\n",
    "            \"limit\": 5\n",
    "        })\n",
    "        \n",
    "        response_text = extract_text_from_result(result)\n",
    "        land_use_data = json.loads(response_text)\n",
    "        \n",
    "        if \"features\" in land_use_data:\n",
    "            features = land_use_data[\"features\"]\n",
    "            if features:\n",
    "                print(f\"✅ Found {len(features)} {land_use_type.lower()} locations around {location_name}\")\n",
    "                \n",
    "                for i, feature in enumerate(features, 1):\n",
    "                    props = feature.get(\"properties\", {})\n",
    "                    site_name = props.get(\"distname1\", f\"{land_use_type} site {i}\")\n",
    "                    print(f\"  {i}. {site_name}\")\n",
    "            else:\n",
    "                print(f\"ℹ️ No {land_use_type.lower()} locations found around {location_name}\")\n",
    "        \n",
    "        return land_use_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {land_use_type} search failed for {location_name}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Perform searches for both locations\n",
    "if session:\n",
    "    print(\"🌍 Performing location-based searches...\")\n",
    "    \n",
    "    for location_key, location_data in LOCATIONS.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📍 Exploring {location_data['name']}\")\n",
    "        print(f\"📊 Coordinates: {location_data['lat']}, {location_data['lon']}\")\n",
    "        print(f\"📦 Search area: {location_data['bbox']}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Search for streets\n",
    "            streets = await search_streets_around_location(\n",
    "                session, \n",
    "                location_data['name'], \n",
    "                location_data['bbox']\n",
    "            )\n",
    "            \n",
    "            # Search for retail locations\n",
    "            retail = await find_land_use_around_location(\n",
    "                session,\n",
    "                location_data['name'],\n",
    "                location_data['bbox'],\n",
    "                \"Retail\"\n",
    "            )\n",
    "            \n",
    "            # Search for transport hubs\n",
    "            transport = await find_land_use_around_location(\n",
    "                session,\n",
    "                location_data['name'], \n",
    "                location_data['bbox'],\n",
    "                \"Transport\"\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Search failed for {location_data['name']}: {e}\")\n",
    "    \n",
    "    print(\"\\n🎉 Location-based searches completed!\")\n",
    "else:\n",
    "    print(\"❌ No active session - please run the connection cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6dead",
   "metadata": {},
   "source": [
    "## 6. Advanced Filtering and Query Examples\n",
    "\n",
    "Let's explore more sophisticated filtering capabilities using CQL (Common Query Language) expressions to find specific types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_advanced_filters(session):\n",
    "    \"\"\"Demonstrate advanced CQL filtering capabilities\"\"\"\n",
    "    print(\"🔍 Demonstrating advanced filtering capabilities...\")\n",
    "    \n",
    "    filter_examples = [\n",
    "        {\n",
    "            \"name\": \"A Roads in Nottingham\",\n",
    "            \"collection\": \"trn-ntwk-street-1\",\n",
    "            \"filter\": \"roadclassification = 'A Road'\",\n",
    "            \"bbox\": LOCATIONS[\"nottingham\"][\"bbox\"],\n",
    "            \"description\": \"Find A roads specifically in Nottingham area\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Open A Roads\",\n",
    "            \"collection\": \"trn-ntwk-street-1\", \n",
    "            \"filter\": \"roadclassification = 'A Road' AND operationalstate = 'Open'\",\n",
    "            \"description\": \"Find A roads that are currently operational\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"High Streets\",\n",
    "            \"collection\": \"trn-ntwk-street-1\",\n",
    "            \"filter\": \"designatedname1_text LIKE '%High%'\",\n",
    "            \"description\": \"Find streets with 'High' in the name\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Retail Areas in Coventry\",\n",
    "            \"collection\": \"lus-fts-site-1\",\n",
    "            \"filter\": \"oslandusetiera = 'Retail'\",\n",
    "            \"bbox\": LOCATIONS[\"coventry\"][\"bbox\"],\n",
    "            \"description\": \"Find retail areas specifically in Coventry\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for example in filter_examples:\n",
    "        print(f\"\\n📋 {example['name']}\")\n",
    "        print(f\"   {example['description']}\")\n",
    "        print(f\"   Filter: {example['filter']}\")\n",
    "        \n",
    "        try:\n",
    "            params = {\n",
    "                \"collection_id\": example['collection'],\n",
    "                \"filter\": example['filter'],\n",
    "                \"limit\": 5\n",
    "            }\n",
    "            \n",
    "            if 'bbox' in example:\n",
    "                params['bbox'] = \",\".join(map(str, example['bbox']))\n",
    "                print(f\"   Area: {example['bbox']}\")\n",
    "            \n",
    "            result = await session.call_tool(\"search_features\", params)\n",
    "            response_text = extract_text_from_result(result)\n",
    "            data = json.loads(response_text)\n",
    "            \n",
    "            feature_count = len(data.get(\"features\", []))\n",
    "            results_summary.append({\n",
    "                \"Query\": example['name'],\n",
    "                \"Collection\": example['collection'],\n",
    "                \"Results Found\": feature_count,\n",
    "                \"Status\": \"✅ Success\" if feature_count > 0 else \"ℹ️ No results\"\n",
    "            })\n",
    "            \n",
    "            if feature_count > 0:\n",
    "                print(f\"   ✅ Found {feature_count} results\")\n",
    "                \n",
    "                # Show details for first few results\n",
    "                features = data[\"features\"][:2]\n",
    "                for i, feature in enumerate(features, 1):\n",
    "                    props = feature.get(\"properties\", {})\n",
    "                    \n",
    "                    if example['collection'] == \"trn-ntwk-street-1\":\n",
    "                        name = props.get(\"designatedname1_text\", \"Unnamed\")\n",
    "                        classification = props.get(\"roadclassification\", \"Unknown\")\n",
    "                        state = props.get(\"operationalstate\", \"Unknown\")\n",
    "                        print(f\"      {i}. {name} ({classification}, {state})\")\n",
    "                    \n",
    "                    elif example['collection'] == \"lus-fts-site-1\":\n",
    "                        name = props.get(\"distname1\", \"Unnamed location\")\n",
    "                        land_use = props.get(\"oslandusetiera\", \"Unknown type\")\n",
    "                        print(f\"      {i}. {name} ({land_use})\")\n",
    "            else:\n",
    "                print(f\"   ℹ️ No results found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "            results_summary.append({\n",
    "                \"Query\": example['name'],\n",
    "                \"Collection\": example['collection'],\n",
    "                \"Results Found\": 0,\n",
    "                \"Status\": f\"❌ Error: {str(e)[:50]}...\"\n",
    "            })\n",
    "    \n",
    "    # Show summary table\n",
    "    print(f\"\\n📊 Summary of Advanced Filter Results:\")\n",
    "    if results_summary:\n",
    "        df = pd.DataFrame(results_summary)\n",
    "        print(df.to_string(index=False))\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Run advanced filtering examples\n",
    "if session:\n",
    "    try:\n",
    "        filter_results = await demonstrate_advanced_filters(session)\n",
    "        print(\"\\n🎉 Advanced filtering examples completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"💥 Advanced filtering failed: {e}\")\n",
    "else:\n",
    "    print(\"❌ No active session - please run the connection cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2757a",
   "metadata": {},
   "source": [
    "## 7. Postcode and Address Searches\n",
    "\n",
    "Let's search for address data using our specific postcodes: NG1 7FG (Nottingham) and CV1 (Coventry area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_addresses_by_postcode(session, postcode_pattern, location_name):\n",
    "    \"\"\"Search for addresses by postcode pattern\"\"\"\n",
    "    print(f\"🏠 Searching for addresses in {postcode_pattern} ({location_name})...\")\n",
    "    \n",
    "    try:\n",
    "        result = await session.call_tool(\"search_features\", {\n",
    "            \"collection_id\": \"adr-fts-addressbasepremium-1\",\n",
    "            \"filter\": f\"postcode LIKE '{postcode_pattern}%'\",\n",
    "            \"limit\": 10\n",
    "        })\n",
    "        \n",
    "        response_text = extract_text_from_result(result)\n",
    "        address_data = json.loads(response_text)\n",
    "        \n",
    "        if \"features\" in address_data:\n",
    "            features = address_data[\"features\"]\n",
    "            if features:\n",
    "                print(f\"✅ Found {len(features)} addresses in {postcode_pattern}\")\n",
    "                \n",
    "                # Create address summary\n",
    "                address_summary = []\n",
    "                for i, feature in enumerate(features[:5], 1):  # Show first 5\n",
    "                    props = feature.get(\"properties\", {})\n",
    "                    address_summary.append({\n",
    "                        \"Address\": props.get(\"address\", \"No address\"),\n",
    "                        \"Postcode\": props.get(\"postcode\", \"No postcode\"),\n",
    "                        \"UPRN\": props.get(\"uprn\", \"No UPRN\"),\n",
    "                        \"Classification\": props.get(\"classification\", \"Unknown\")\n",
    "                    })\n",
    "                \n",
    "                if address_summary:\n",
    "                    df = pd.DataFrame(address_summary)\n",
    "                    print(df.to_string(index=False))\n",
    "                \n",
    "                return features\n",
    "            else:\n",
    "                print(f\"ℹ️ No addresses found for {postcode_pattern}\")\n",
    "        \n",
    "        return []\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Address search failed for {postcode_pattern}: {e}\")\n",
    "        return []\n",
    "\n",
    "async def get_feature_by_id(session, collection_id, feature_id):\n",
    "    \"\"\"Get specific feature details by ID\"\"\"\n",
    "    print(f\"🔍 Getting feature details for {feature_id} in {collection_id}...\")\n",
    "    \n",
    "    try:\n",
    "        result = await session.call_tool(\"get_feature\", {\n",
    "            \"collection_id\": collection_id,\n",
    "            \"feature_id\": feature_id\n",
    "        })\n",
    "        \n",
    "        response_text = extract_text_from_result(result)\n",
    "        feature_data = json.loads(response_text)\n",
    "        \n",
    "        if \"properties\" in feature_data:\n",
    "            print(\"✅ Feature details retrieved:\")\n",
    "            props = feature_data[\"properties\"]\n",
    "            \n",
    "            # Show key properties\n",
    "            for key, value in list(props.items())[:5]:  # Show first 5 properties\n",
    "                print(f\"   {key}: {value}\")\n",
    "            \n",
    "            if len(props) > 5:\n",
    "                print(f\"   ... and {len(props) - 5} more properties\")\n",
    "                \n",
    "        return feature_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Feature retrieval failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Search for addresses in our example postcodes\n",
    "if session:\n",
    "    print(\"🏠 Performing postcode and address searches...\")\n",
    "    \n",
    "    # Search Nottingham NG1 7FG area\n",
    "    nottingham_addresses = await search_addresses_by_postcode(\n",
    "        session, \"NG1\", \"Nottingham\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Search Coventry CV1 area\n",
    "    coventry_addresses = await search_addresses_by_postcode(\n",
    "        session, \"CV1\", \"Coventry\" \n",
    "    )\n",
    "    \n",
    "    # If we found any addresses, get detailed info for the first one\n",
    "    if nottingham_addresses:\n",
    "        print(f\"\\n🔍 Getting detailed information for first Nottingham address...\")\n",
    "        first_address = nottingham_addresses[0]\n",
    "        address_props = first_address.get(\"properties\", {})\n",
    "        if \"id\" in first_address:\n",
    "            feature_details = await get_feature_by_id(\n",
    "                session,\n",
    "                \"adr-fts-addressbasepremium-1\", \n",
    "                first_address[\"id\"]\n",
    "            )\n",
    "    \n",
    "    print(\"\\n🎉 Postcode and address searches completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No active session - please run the connection cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f435b",
   "metadata": {},
   "source": [
    "## 8. Visualization and Summary\n",
    "\n",
    "Let's create some simple visualizations of our search results and summarize what we've discovered about Nottingham NG1 7FG and Coventry CV1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary visualization of our locations\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Location coordinates\n",
    "locations_df = pd.DataFrame([\n",
    "    {\"Location\": \"Nottingham NG1 7FG\", \"Latitude\": 52.9548, \"Longitude\": -1.1543},\n",
    "    {\"Location\": \"Coventry CV1\", \"Latitude\": 52.4081, \"Longitude\": -1.5101}\n",
    "])\n",
    "\n",
    "ax1.scatter(locations_df[\"Longitude\"], locations_df[\"Latitude\"], s=100, alpha=0.7)\n",
    "for i, row in locations_df.iterrows():\n",
    "    ax1.annotate(row[\"Location\"], (row[\"Longitude\"], row[\"Latitude\"]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax1.set_xlabel(\"Longitude\")\n",
    "ax1.set_ylabel(\"Latitude\") \n",
    "ax1.set_title(\"Example Locations\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bounding box visualization\n",
    "bbox_data = []\n",
    "for name, loc in LOCATIONS.items():\n",
    "    bbox = loc[\"bbox\"]\n",
    "    bbox_data.append({\n",
    "        \"Location\": loc[\"name\"],\n",
    "        \"Bbox Width\": bbox[2] - bbox[0],  # max_lon - min_lon\n",
    "        \"Bbox Height\": bbox[3] - bbox[1]  # max_lat - min_lat\n",
    "    })\n",
    "\n",
    "bbox_df = pd.DataFrame(bbox_data)\n",
    "bbox_df.plot(x=\"Location\", y=[\"Bbox Width\", \"Bbox Height\"], kind=\"bar\", ax=ax2)\n",
    "ax2.set_title(\"Search Area Sizes\")\n",
    "ax2.set_ylabel(\"Degrees\")\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"📊 OS MCP Server Examples Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"📍 Locations explored: {len(LOCATIONS)}\")\n",
    "\n",
    "for name, loc in LOCATIONS.items():\n",
    "    print(f\"\\n🌍 {loc['name']}:\")\n",
    "    print(f\"   📍 Coordinates: {loc['lat']}, {loc['lon']}\")\n",
    "    print(f\"   📦 Search area: {loc['bbox']}\")\n",
    "    print(f\"   📮 Postcode: {loc['postcode']}\")\n",
    "\n",
    "print(f\"\\n🔧 Operations performed:\")\n",
    "print(f\"   ✅ Server connection and authentication\")\n",
    "print(f\"   ✅ Workflow context retrieval\")\n",
    "print(f\"   ✅ Collection discovery\")\n",
    "print(f\"   ✅ Location-based street searches\")\n",
    "print(f\"   ✅ Land use feature searches\")\n",
    "print(f\"   ✅ Advanced CQL filtering\")\n",
    "print(f\"   ✅ Postcode-based address searches\")\n",
    "\n",
    "print(f\"\\n💡 Key learnings:\")\n",
    "print(f\"   • Always call get_workflow_context() first\")\n",
    "print(f\"   • Use exact enum values for precise filtering\")\n",
    "print(f\"   • Bounding boxes help focus searches geographically\")\n",
    "print(f\"   • CQL filters enable sophisticated queries\")\n",
    "print(f\"   • Multiple data collections available (streets, addresses, land use)\")\n",
    "\n",
    "print(f\"\\n🎯 Next steps:\")\n",
    "print(f\"   • Explore additional collections and their queryables\")\n",
    "print(f\"   • Try more complex CQL filter expressions\")\n",
    "print(f\"   • Experiment with different geographic areas\")\n",
    "print(f\"   • Integrate with mapping libraries for visualization\")\n",
    "\n",
    "print(f\"\\n🎉 OS MCP Server examples completed successfully!\")\n",
    "print(f\"   Ready to explore UK geospatial data! 🗺️\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83d8e1",
   "metadata": {},
   "source": [
    "## 9. Cleanup and Next Steps\n",
    "\n",
    "Finally, let's clean up our connections and provide guidance for further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up connections\n",
    "if session:\n",
    "    try:\n",
    "        await session.__aexit__(None, None, None)\n",
    "        print(\"✅ MCP session closed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Error closing session: {e}\")\n",
    "\n",
    "if client_manager:\n",
    "    try:\n",
    "        await client_manager.__aexit__(None, None, None)\n",
    "        print(\"✅ Client connection closed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Error closing client: {e}\")\n",
    "\n",
    "# Stop the server if we started it in this notebook\n",
    "if 'server_process' in globals() and server_process is not None:\n",
    "    print(\"\\n🛑 Stopping OS MCP Server that was started by this notebook...\")\n",
    "    try:\n",
    "        import os\n",
    "        import signal\n",
    "        # Kill the entire process group to ensure all child processes are terminated\n",
    "        os.killpg(os.getpgid(server_process.pid), signal.SIGTERM)\n",
    "        server_process.wait(timeout=5)  # Wait up to 5 seconds for graceful shutdown\n",
    "        print(\"✅ Server stopped successfully\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"⚠️ Server didn't stop gracefully, forcing termination...\")\n",
    "        os.killpg(os.getpgid(server_process.pid), signal.SIGKILL)\n",
    "        print(\"✅ Server force-stopped\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Error stopping server: {e}\")\n",
    "        print(\"💡 You may need to stop it manually if it's still running\")\n",
    "    \n",
    "    server_process = None\n",
    "else:\n",
    "    print(\"\\n⚠️ Server was not started by this notebook - leaving it running\")\n",
    "    print(\"💡 If you want to stop the server, use Ctrl+C in the terminal where it's running\")\n",
    "\n",
    "print(\"\\n🎯 Exploration Complete!\")\n",
    "print(\"\\n📚 Additional Resources:\")\n",
    "print(\"   • OS Data Hub: https://osdatahub.os.uk/\")\n",
    "print(\"   • OS MCP Server GitHub: Your project repository\")\n",
    "print(\"   • More examples: Check the examples/ directory\")\n",
    "\n",
    "print(\"\\n🛠️ Try These Next:\")\n",
    "print(\"   • Explore different collections with get_collection_info()\")\n",
    "print(\"   • Try get_collection_queryables() to see all available filters\")\n",
    "print(\"   • Experiment with different bounding boxes\")\n",
    "print(\"   • Combine multiple filter criteria with AND/OR\")\n",
    "print(\"   • Search for specific street names or building types\")\n",
    "\n",
    "print(\"\\n💡 Pro Tips:\")\n",
    "print(\"   • Use tighter bounding boxes for faster searches\")\n",
    "print(\"   • Check enum values in workflow context for exact filtering\")\n",
    "print(\"   • The server has built-in rate limiting for protection\") \n",
    "print(\"   • Always handle errors gracefully in production code\")\n",
    "\n",
    "print(\"\\n🌟 Happy exploring UK geospatial data with OS MCP Server! 🗺️\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
